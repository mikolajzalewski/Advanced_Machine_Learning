{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from boruta import BorutaPy\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SequentialFeatureSelector, RFE, mutual_info_classif, SelectKBest, f_classif, chi2\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV, ElasticNet\n",
    "from feature_selection_package.evaluation import performance_score, single_evaluation, full_evaluation\n",
    "from feature_selection_package.feature_selectors import CorrelationSelector, MutualInformationSelector, RandomForestSelector, EnsembleSelector\n",
    "from boruta import BorutaPy\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data artificial\n",
    "artificial_train_data = pd.read_csv('data/artificial_train.data',header=None,sep=' ').dropna(axis=1)\n",
    "artificial_train_labels = pd.read_csv('data/artificial_train.labels',header=None,sep=' ').dropna(axis=1)\n",
    "artificial_valid_data = pd.read_csv('data/artificial_valid.data',header=None,sep=' ').dropna(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load data sms\n",
    "sms_train = pd.read_csv('data/sms_train.csv')\n",
    "sms_train_data, sms_train_labels = sms_train.iloc[:, 1], sms_train.iloc[:, 0]\n",
    "\n",
    "sms_test_data = pd.read_csv('data/sms_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I dont. Can you send it to me. Plus how's mode.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Or i go home first lar ü wait 4 me lor.. I put...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Me, i dont know again oh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>I'll see, but prolly yeah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Night has ended for another day, morning has c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4567</th>\n",
       "      <td>0</td>\n",
       "      <td>Aight, tomorrow around  &amp;lt;#&amp;gt;  it is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4568</th>\n",
       "      <td>1</td>\n",
       "      <td>FREE MSG:We billed your mobile number by mista...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4569</th>\n",
       "      <td>0</td>\n",
       "      <td>Lol! Oops sorry! Have fun.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4570</th>\n",
       "      <td>0</td>\n",
       "      <td>alright, I'll make sure the car is back tonight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4571</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah it's straight, if you can just bring bud o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                            message\n",
       "0         0    I dont. Can you send it to me. Plus how's mode.\n",
       "1         0  Or i go home first lar ü wait 4 me lor.. I put...\n",
       "2         0                           Me, i dont know again oh\n",
       "3         0                          I'll see, but prolly yeah\n",
       "4         0  Night has ended for another day, morning has c...\n",
       "...     ...                                                ...\n",
       "4567      0           Aight, tomorrow around  &lt;#&gt;  it is\n",
       "4568      1  FREE MSG:We billed your mobile number by mista...\n",
       "4569      0                        Lol! Oops sorry! Have fun. \n",
       "4570      0    alright, I'll make sure the car is back tonight\n",
       "4571      0  Nah it's straight, if you can just bring bud o...\n",
       "\n",
       "[4572 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "910\n"
     ]
    }
   ],
   "source": [
    "m = 0\n",
    "for i in sms_train.message:\n",
    "    if len(i) > m:\n",
    "        m = len(i)\n",
    "print(m)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm1 = SVC(kernel='rbf', C=1, random_state=0)\n",
    "svm2 = SVC(kernel='linear', C=1, random_state=0)\n",
    "\n",
    "tree = DecisionTreeClassifier(criterion='entropy', max_depth=5, random_state=0)\n",
    "xgboost = XGBClassifier(learning_rate=0.1, n_estimators=100, max_depth=5, random_state=0)\n",
    "rfc = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=0)\n",
    "\n",
    "logreg = LogisticRegression(penalty='l2', C=1, random_state=0)\n",
    "\n",
    "classifiers = np.array([svm1, svm2, tree, xgboost, rfc, logreg])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality reduction methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = [10, 20, 50, 80]\n",
    "pca_results = pd.DataFrame()\n",
    "for n in n_features:\n",
    "    selector = [PCA(n_components=n)]\n",
    "    pca_df = full_evaluation(train_data, train_labels, valid_data, valid_labels, selector, classifiers)\n",
    "    pca_results = pd.concat([pca_results, pca_df])\n",
    "pca_results.to_csv('data/pca.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapper methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = [100, 1000, 7000]\n",
    "selector = [RFE(estimator=RandomForestClassifier(n_estimators=100, max_depth=3), n_features_to_select=7000, step=1, verbose=0)]\n",
    "rfe_results = full_evaluation(train_data, train_labels, valid_data, valid_labels, selector, classifiers)\n",
    "rfe_results.to_csv('data/RFE.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = [SequentialFeatureSelector(estimator=RandomForestClassifier(n_estimators=100, max_depth=3), n_features_to_select=100, direction='forward')]\n",
    "sfs_results = full_evaluation(train_data, train_labels, valid_data, valid_labels, selector, classifiers)\n",
    "sfs_results.to_csv('data/SFS.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = [SequentialFeatureSelector(estimator=RandomForestClassifier(n_estimators=100, max_depth=3), n_features_to_select=100, direction='backward')]\n",
    "sbs_results = full_evaluation(train_data, train_labels, valid_data, valid_labels, selector, classifiers)\n",
    "sbs_results.to_csv('data/SBS.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeded methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_df = pd.DataFrame(columns=['Selector', 'Classifier', 'Number_of_Features', 'Accuracy', 'Performance_score'])\n",
    "Cs = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
    "for C in Cs:\n",
    "    lasso = LogisticRegression(penalty='l1', C=C, solver='liblinear', random_state=0)\n",
    "    lasso.fit(train_data, train_labels)\n",
    "    n_features = sum(lasso.coef_[0] != 0)\n",
    "    score = lasso.score(valid_data, valid_labels)\n",
    "    perf_score = performance_score(score, n_features)\n",
    "    lasso_df = pd.concat([lasso_df, pd.DataFrame({'Selector': ['Lasso'], 'Classifier': ['Lasso'], 'Number_of_Features': [n_features], 'Accuracy': [score], 'Performance_score': [perf_score]})], ignore_index=True)\n",
    "\n",
    "lasso_df.to_csv('data/lasso.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
    "l1_ratio = [0.9, 0.95, 0.98]\n",
    "elastic_df = pd.DataFrame(columns=['Selector', 'Classifier', 'Number_of_Features', 'Accuracy', 'Performance_score', 'alpha', 'l1_ratio'])\n",
    "for ratio in l1_ratio:\n",
    "    for alpha in alphas:\n",
    "        elastic = ElasticNet(alpha=alpha, l1_ratio=ratio, random_state=0, max_iter = 10000)\n",
    "        elastic.fit(train_data, train_labels)\n",
    "        n_features = sum(elastic.coef_!= 0)\n",
    "        score = elastic.score(valid_data, valid_labels)\n",
    "        perf_score = performance_score(score, n_features)\n",
    "        elastic_df = pd.concat([elastic_df, pd.DataFrame({'Selector': ['Lasso'], 'Classifier': ['Lasso'], 'Number_of_Features': [n_features], 'Accuracy': [score], 'Performance_score': [perf_score], \"alpha\": [alpha], \"l1_ratio\": [ratio]})], ignore_index=True)\n",
    "\n",
    "elastic_df.to_csv('data/elasticNet.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "elasticNet = pd.read_csv('data/elasticNet.csv')\n",
    "elasticNet['Selector'] = 'ElasticNet'\n",
    "elasticNet['Classifier'] = 'ElasticNet'\n",
    "elasticNet.to_csv('data/elasticNet.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = [10, 50, 100, 200, 500, 1000, 2000, 5000, 7000]\n",
    "forest_results = pd.DataFrame()\n",
    "for n in n_features:\n",
    "    selector = [RandomForestSelector(n_features=n)]\n",
    "    df = full_evaluation(train_data, train_labels, valid_data, valid_labels, selector, classifiers)\n",
    "    forest_results = pd.concat([forest_results, df])\n",
    "forest_results.to_csv('data/forest.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = [10, 50, 100, 200, 500, 1000, 2000, 5000, 7000]\n",
    "corr_results = pd.DataFrame()\n",
    "for n in n_features:\n",
    "    selector = [CorrelationSelector(n_features=n)]\n",
    "    df = full_evaluation(train_data, train_labels, valid_data, valid_labels, selector, classifiers)\n",
    "    corr_results = pd.concat([corr_results, df])\n",
    "corr_results.to_csv('data/corr.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = [10, 50, 100, 200, 500, 1000, 2000, 5000, 7000]\n",
    "mutual_results = pd.DataFrame()\n",
    "for n in n_features:\n",
    "    selector = [MutualInformationSelector(n_features=n)]\n",
    "    df = full_evaluation(train_data, train_labels, valid_data, valid_labels, selector, classifiers)\n",
    "    mutual_results = pd.concat([mutual_results, df])\n",
    "mutual_results.to_csv('data/mutual.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select K - Best"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = [10, 50, 100, 200, 500, 1000, 2000, 5000, 7000]\n",
    "anova_results = pd.DataFrame()\n",
    "for n in n_features:\n",
    "    selector = [SelectKBest(f_classif, k=n)]\n",
    "    df = full_evaluation(train_data, train_labels, valid_data, valid_labels, selector, classifiers)\n",
    "    anova_results = pd.concat([anova_results, df])\n",
    "anova_results.to_csv('data/anova.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = [10, 50, 100, 200, 500, 1000, 2000, 5000, 8000]\n",
    "chi2_results = pd.DataFrame()\n",
    "for n in n_features:\n",
    "    selector = [SelectKBest(chi2, k=n)]\n",
    "    df = full_evaluation(train_data, train_labels, valid_data, valid_labels, selector, classifiers)\n",
    "    chi2_results = pd.concat([chi2_results, df])\n",
    "chi2_results.to_csv('data/chi2.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid + wrapper"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boruta algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = [BorutaPy(estimator=RandomForestClassifier(n_estimators=100, max_depth=3), n_estimators='auto', verbose=1, random_state=0)]\n",
    "boruta_results = full_evaluation(train_data, train_labels, valid_data, valid_labels, selector, classifiers)\n",
    "boruta_results.to_csv('data/boruta.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector1 = RandomForestSelector(n_features=500)\n",
    "selector2 = RFE(estimator=RandomForestClassifier(n_estimators=100, max_depth=3), n_features_to_select=100, step=1, verbose=1)\n",
    "selectors = [[selector1, selector2]]\n",
    "stack_results = full_evaluation(train_data, train_labels, valid_data, valid_labels, selectors, classifiers)\n",
    "stack_results.to_csv('data/stack.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = [10, 50, 100, 200, 500, 1000, 2000, 5000, 7000]\n",
    "ensemble_results = pd.DataFrame()\n",
    "for n in n_features:\n",
    "    selectors = [RandomForestSelector(n_features=n), SelectKBest(f_classif, k=n), SelectKBest(chi2, k=n), CorrelationSelector(n_features=n), MutualInformationSelector(n_features=n)]\n",
    "    ensemble = [EnsembleSelector(selectors=selectors)]\n",
    "    df = full_evaluation(train_data, train_labels, valid_data, valid_labels, ensemble, classifiers)\n",
    "    ensemble_results = pd.concat([ensemble_results, df])\n",
    "    \n",
    "ensemble_results.to_csv('data/ensemble.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
