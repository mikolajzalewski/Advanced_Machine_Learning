{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from boruta import BorutaPy\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SequentialFeatureSelector, RFE, mutual_info_classif, SelectKBest, f_classif, chi2\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV, ElasticNet\n",
    "from evaluation import performance_score, single_evaluation, full_evaluation\n",
    "from feature_selectors import CorrelationSelector, MutualInformationSelector, RandomForestSelector\n",
    "from boruta import BorutaPy\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read arcene_train.data\n",
    "train_data = pd.read_csv('Arcene-dataset/arcene_train.data', sep=' ', header=None)\n",
    "train_data = train_data.drop(train_data.columns[10000], axis=1)\n",
    "\n",
    "# Read arcene_train.labels\n",
    "train_labels = pd.read_csv('Arcene-dataset/arcene_train.labels', sep=' ', header=None).values.ravel()\n",
    "train_labels = pd.Series(np.where(train_labels == -1, 0, train_labels))\n",
    "\n",
    "# Read arcene_valid.data\n",
    "valid_data = pd.read_csv('Arcene-dataset/arcene_valid.data', sep=' ', header=None)\n",
    "valid_data = valid_data.drop(valid_data.columns[10000], axis=1)\n",
    "\n",
    "# Read arcene_valid.labels\n",
    "valid_labels = pd.read_csv('Arcene-dataset/arcene_valid.labels', sep=' ', header=None).values.ravel()\n",
    "valid_labels = pd.Series(np.where(valid_labels == -1, 0, valid_labels))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm1 = SVC(kernel='rbf', C=1, random_state=0)\n",
    "svm2 = SVC(kernel='linear', C=1, random_state=0)\n",
    "\n",
    "tree = DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=0)\n",
    "xgboost = XGBClassifier(learning_rate=0.1, n_estimators=100, max_depth=5, random_state=0)\n",
    "rfc = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=0)\n",
    "\n",
    "classifiers = np.array([svm1, svm2, tree, xgboost, rfc])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality reduction methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df = full_evaluation(train_data, train_labels, valid_data, valid_labels, [PCA()], classifiers, [10, 20, 50, 80])\n",
    "pca_df.to_csv('data/pca2.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapper methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_df = pd.DataFrame(columns=['Selector', 'Classifier', 'Number_of_Features', 'Accuracy', 'Performance_score'])\n",
    "selector = RFE(estimator=RandomForestClassifier(n_estimators=100, max_depth=3), n_features_to_select=7000, step=1, verbose=0)\n",
    "classifier = rfc\n",
    "\n",
    "accuracy, perf_score, n_features = single_evaluation(train_data, train_labels, valid_data, valid_labels, selector, classifier)\n",
    "df = pd.DataFrame({'Selector': ['Boruta'], 'Classifier': [classifier.__class__.__name__], 'Number_of_Features': [n_features], 'Accuracy': [accuracy], 'Performance_score': [perf_score]})\n",
    "rfe_df = pd.concat([rfe_df, df], ignore_index=True)\n",
    "\n",
    "rfe_df.to_csv('data/rfe.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs_df = pd.DataFrame(columns=['Selector', 'Classifier', 'Number_of_Features', 'Accuracy', 'Performance_score'])\n",
    "sfs = SequentialFeatureSelector(estimator=RandomForestClassifier(n_estimators=100, max_depth=3), n_features_to_select=100, direction='forward')\n",
    "classifier = rfc\n",
    "\n",
    "accuracy, perf_score, n_features = single_evaluation(train_data, train_labels, valid_data, valid_labels, selector, classifier)\n",
    "df = pd.DataFrame({'Selector': ['Boruta'], 'Classifier': [classifier.__class__.__name__], 'Number_of_Features': [n_features], 'Accuracy': [accuracy], 'Performance_score': [perf_score]})\n",
    "sfs_df = pd.concat([sfs_df, df], ignore_index=True)\n",
    "\n",
    "sfs_df.to_csv('data/sfs.csv', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbs_df = pd.DataFrame(columns=['Selector', 'Classifier', 'Number_of_Features', 'Accuracy', 'Performance_score'])\n",
    "sbs = SequentialFeatureSelector(estimator=RandomForestClassifier(n_estimators=100, max_depth=3), n_features_to_select=100, direction='backward')\n",
    "classifier = rfc\n",
    "\n",
    "accuracy, perf_score, n_features = single_evaluation(train_data, train_labels, valid_data, valid_labels, selector, classifier)\n",
    "df = pd.DataFrame({'Selector': ['Boruta'], 'Classifier': [classifier.__class__.__name__], 'Number_of_Features': [n_features], 'Accuracy': [accuracy], 'Performance_score': [perf_score]})\n",
    "sbs_df = pd.concat([sbs_df, df], ignore_index=True)\n",
    "\n",
    "sbs_df.to_csv('data/sbs.csv', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeded methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_df = pd.DataFrame(columns=['Selector', 'Classifier', 'Number_of_Features', 'Accuracy', 'Performance_score'])\n",
    "Cs = [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
    "for C in Cs:\n",
    "    lasso = LogisticRegression(penalty='l1', C=C, solver='liblinear', random_state=0)\n",
    "    lasso.fit(train_data, train_labels)\n",
    "    n_features = sum(lasso.coef_[0] != 0)\n",
    "    score = lasso.score(valid_data, valid_labels)\n",
    "    perf_score = performance_score(score, n_features)\n",
    "    lasso_df = pd.concat([lasso_df, pd.DataFrame({'Selector': ['Lasso'], 'Classifier': ['Lasso'], 'Number_of_Features': [n_features], 'Accuracy': [score], 'Performance_score': [perf_score]})], ignore_index=True)\n",
    "\n",
    "lasso_df.to_csv('data/lasso.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "l1_ratio = [0.5, 0.7, 0.9]\n",
    "elastic_df = pd.DataFrame(columns=['Selector', 'Classifier', 'Number_of_Features', 'Accuracy', 'Performance_score', 'alpha', 'l1_ratio'])\n",
    "for ratio in l1_ratio:\n",
    "    for alpha in alphas:\n",
    "        elastic = ElasticNet(alpha=alpha, l1_ratio=ratio, random_state=0, max_iter = 2000)\n",
    "        elastic.fit(train_data, train_labels)\n",
    "        n_features = sum(elastic.coef_!= 0)\n",
    "        score = elastic.score(valid_data, valid_labels)\n",
    "        perf_score = performance_score(score, n_features)\n",
    "        elastic_df = pd.concat([elastic_df, pd.DataFrame({'Selector': ['Lasso'], 'Classifier': ['Lasso'], 'Number_of_Features': [n_features], 'Accuracy': [score], 'Performance_score': [perf_score], \"alpha\": [alpha], \"l1_ratio\": [ratio]})], ignore_index=True)\n",
    "\n",
    "elastic_df.to_csv('data/elasticNet.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfs_df = full_evaluation(train_data, train_labels, valid_data, valid_labels, [RandomForestSelector()], classifiers, n_features = [10, 50, 100, 200, 500, 1000, 2000, 5000, 10000])\n",
    "rfs_df.to_csv('data/rfs2.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = full_evaluation(train_data, train_labels, valid_data, valid_labels, [CorrelationSelector()], classifiers, n_features = [10, 50, 100, 200, 500, 1000, 2000, 5000, 10000])\n",
    "corr_df.to_csv('data/corr2.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_df = full_evaluation(train_data, train_labels, valid_data, valid_labels, [MutualInformationSelector()], classifiers, n_features = [10, 50, 100, 200, 500, 1000, 2000, 5000, 10000])\n",
    "mutual_df.to_csv('data/mutual2.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select K - Best"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = [10, 50, 100, 200, 500, 1000, 2000, 5000]\n",
    "selector = SelectKBest(f_classif)\n",
    "anova_df = full_evaluation(train_data, train_labels, valid_data, valid_labels, [selector], classifiers, n_features)\n",
    "anova_df.to_csv('data/anova.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = [10, 50, 100, 200, 500, 1000, 2000, 5000]\n",
    "selector = SelectKBest(chi2)\n",
    "chi2_df = full_evaluation(train_data, train_labels, valid_data, valid_labels, [selector], classifiers, n_features)\n",
    "chi2_df.to_csv('data/chi2.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid + wrapper"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boruta algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boruta_df = pd.DataFrame(columns=['Selector', 'Classifier', 'Number_of_Features', 'Accuracy', 'Performance_score'])\n",
    "selector = BorutaPy(estimator=RandomForestClassifier(n_estimators=100, max_depth=3), n_estimators='auto', verbose=1, random_state=0)\n",
    "for classifier in classifiers:\n",
    "    accuracy, perf_score, n_features = single_evaluation(train_data, train_labels, valid_data, valid_labels, selector, classifier)\n",
    "    df = pd.DataFrame({'Selector': ['Boruta'], 'Classifier': [classifier.__class__.__name__], 'Number_of_Features': [n_features], 'Accuracy': [accuracy], 'Performance_score': [perf_score]})\n",
    "    boruta_df = pd.concat([boruta_df, df], ignore_index=True)\n",
    "\n",
    "boruta_df.to_csv('data/boruta2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
