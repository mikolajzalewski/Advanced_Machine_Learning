{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from boruta import BorutaPy\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SequentialFeatureSelector, RFE, mutual_info_classif, SelectKBest, f_classif, chi2\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV, ElasticNet\n",
    "from feature_selection_package.evaluation import performance_score, single_evaluation, full_evaluation\n",
    "from feature_selection_package.feature_selectors import CorrelationSelector, MutualInformationSelector, RandomForestSelector, EnsembleSelector\n",
    "from boruta import BorutaPy\n",
    "from feature_selection_package.sms_data_creation import get_word_counts_train_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data sms\n",
    "sms_train = pd.read_csv('data/sms_train.csv')\n",
    "sms_train_data, sms_train_labels = sms_train.iloc[:, 1], sms_train.iloc[:, 0]\n",
    "\n",
    "sms_test_data = pd.read_csv('data/sms_test.csv')\n",
    "sms_test = sms_test_data.copy()\n",
    "sms_test['label'] = np.nan\n",
    "\n",
    "preprocessed_sms_train , preprocessed_sms_test = get_word_counts_train_test(sms_train, sms_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversample\n",
    "from imblearn.over_sampling import SMOTE\n",
    "oversample = SMOTE()\n",
    "preprocessed_sms_train, sms_train_labels = oversample.fit_resample(preprocessed_sms_train, sms_train_labels)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = preprocessed_sms_train.iloc[:np.round(len(preprocessed_sms_train)*0.8).astype(int), 1:]\n",
    "train_labels = preprocessed_sms_train.iloc[:np.round(len(preprocessed_sms_train)*0.8).astype(int), 0]\n",
    "valid_data = preprocessed_sms_train.iloc[np.round(len(preprocessed_sms_train)*0.8).astype(int):, 1:]\n",
    "valid_labels = preprocessed_sms_train.iloc[np.round(len(preprocessed_sms_train)*0.8).astype(int):, 0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if train and valid data is balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of observations in each class in train set: (array([0, 1], dtype=int64), array([3170,  488], dtype=int64))\n",
      "number of observations in each class in validation set: (array([0, 1], dtype=int64), array([789, 125], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print('number of observations in each class in train set:', np.unique(train_labels, return_counts=True))\n",
    "print('number of observations in each class in validation set:', np.unique(valid_labels, return_counts=True))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm1 = SVC(kernel='rbf', C=1, random_state=0)\n",
    "svm2 = SVC(kernel='linear', C=1, random_state=0)\n",
    "\n",
    "tree = DecisionTreeClassifier(criterion='entropy', max_depth=5, random_state=0)\n",
    "xgboost = XGBClassifier(learning_rate=0.1, n_estimators=100, max_depth=5, random_state=0)\n",
    "rfc = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=0)\n",
    "\n",
    "logreg = LogisticRegression(penalty='l2', C=1, random_state=0, max_iter=1000)\n",
    "\n",
    "classifiers = np.array([svm1, svm2, tree, xgboost, rfc, logreg])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality reduction methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = [10, 20, 30, 50, 75]\n",
    "pca_results = pd.DataFrame()\n",
    "for n in n_features:\n",
    "    selector = [PCA(n_components=n)]\n",
    "    pca_df = full_evaluation(train_data, train_labels, valid_data, valid_labels, selector, classifiers, dataset_type='sms')\n",
    "    pca_results = pd.concat([pca_results, pca_df])\n",
    "pca_results.to_csv('data/pca.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Selector</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Number_of_Features</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Performance_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PCA</td>\n",
       "      <td>SVC_rbf</td>\n",
       "      <td>10</td>\n",
       "      <td>0.912198</td>\n",
       "      <td>0.9122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PCA</td>\n",
       "      <td>SVC_linear</td>\n",
       "      <td>10</td>\n",
       "      <td>0.894099</td>\n",
       "      <td>0.8941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PCA</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>10</td>\n",
       "      <td>0.929029</td>\n",
       "      <td>0.9290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PCA</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>10</td>\n",
       "      <td>0.941465</td>\n",
       "      <td>0.9415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PCA</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>10</td>\n",
       "      <td>0.901465</td>\n",
       "      <td>0.9015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PCA</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>10</td>\n",
       "      <td>0.870733</td>\n",
       "      <td>0.8707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PCA</td>\n",
       "      <td>SVC_rbf</td>\n",
       "      <td>20</td>\n",
       "      <td>0.906099</td>\n",
       "      <td>0.9061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PCA</td>\n",
       "      <td>SVC_linear</td>\n",
       "      <td>20</td>\n",
       "      <td>0.898733</td>\n",
       "      <td>0.8987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PCA</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>20</td>\n",
       "      <td>0.941663</td>\n",
       "      <td>0.9417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PCA</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>20</td>\n",
       "      <td>0.937465</td>\n",
       "      <td>0.9375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PCA</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>20</td>\n",
       "      <td>0.858099</td>\n",
       "      <td>0.8581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PCA</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>20</td>\n",
       "      <td>0.895366</td>\n",
       "      <td>0.8954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PCA</td>\n",
       "      <td>SVC_rbf</td>\n",
       "      <td>50</td>\n",
       "      <td>0.918099</td>\n",
       "      <td>0.9181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PCA</td>\n",
       "      <td>SVC_linear</td>\n",
       "      <td>50</td>\n",
       "      <td>0.925465</td>\n",
       "      <td>0.9255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PCA</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>50</td>\n",
       "      <td>0.936831</td>\n",
       "      <td>0.9368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PCA</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>50</td>\n",
       "      <td>0.949465</td>\n",
       "      <td>0.9495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PCA</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>50</td>\n",
       "      <td>0.866733</td>\n",
       "      <td>0.8667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PCA</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>50</td>\n",
       "      <td>0.915366</td>\n",
       "      <td>0.9154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PCA</td>\n",
       "      <td>SVC_rbf</td>\n",
       "      <td>80</td>\n",
       "      <td>0.923366</td>\n",
       "      <td>0.9234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PCA</td>\n",
       "      <td>SVC_linear</td>\n",
       "      <td>80</td>\n",
       "      <td>0.930099</td>\n",
       "      <td>0.9301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PCA</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>80</td>\n",
       "      <td>0.898099</td>\n",
       "      <td>0.8981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PCA</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>80</td>\n",
       "      <td>0.937465</td>\n",
       "      <td>0.9375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PCA</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>80</td>\n",
       "      <td>0.823366</td>\n",
       "      <td>0.8234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PCA</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>80</td>\n",
       "      <td>0.915366</td>\n",
       "      <td>0.9154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Selector              Classifier  Number_of_Features  Accuracy  \\\n",
       "0       PCA                 SVC_rbf                  10  0.912198   \n",
       "1       PCA              SVC_linear                  10  0.894099   \n",
       "2       PCA  DecisionTreeClassifier                  10  0.929029   \n",
       "3       PCA           XGBClassifier                  10  0.941465   \n",
       "4       PCA  RandomForestClassifier                  10  0.901465   \n",
       "5       PCA      LogisticRegression                  10  0.870733   \n",
       "6       PCA                 SVC_rbf                  20  0.906099   \n",
       "7       PCA              SVC_linear                  20  0.898733   \n",
       "8       PCA  DecisionTreeClassifier                  20  0.941663   \n",
       "9       PCA           XGBClassifier                  20  0.937465   \n",
       "10      PCA  RandomForestClassifier                  20  0.858099   \n",
       "11      PCA      LogisticRegression                  20  0.895366   \n",
       "12      PCA                 SVC_rbf                  50  0.918099   \n",
       "13      PCA              SVC_linear                  50  0.925465   \n",
       "14      PCA  DecisionTreeClassifier                  50  0.936831   \n",
       "15      PCA           XGBClassifier                  50  0.949465   \n",
       "16      PCA  RandomForestClassifier                  50  0.866733   \n",
       "17      PCA      LogisticRegression                  50  0.915366   \n",
       "18      PCA                 SVC_rbf                  80  0.923366   \n",
       "19      PCA              SVC_linear                  80  0.930099   \n",
       "20      PCA  DecisionTreeClassifier                  80  0.898099   \n",
       "21      PCA           XGBClassifier                  80  0.937465   \n",
       "22      PCA  RandomForestClassifier                  80  0.823366   \n",
       "23      PCA      LogisticRegression                  80  0.915366   \n",
       "\n",
       "    Performance_score  \n",
       "0              0.9122  \n",
       "1              0.8941  \n",
       "2              0.9290  \n",
       "3              0.9415  \n",
       "4              0.9015  \n",
       "5              0.8707  \n",
       "6              0.9061  \n",
       "7              0.8987  \n",
       "8              0.9417  \n",
       "9              0.9375  \n",
       "10             0.8581  \n",
       "11             0.8954  \n",
       "12             0.9181  \n",
       "13             0.9255  \n",
       "14             0.9368  \n",
       "15             0.9495  \n",
       "16             0.8667  \n",
       "17             0.9154  \n",
       "18             0.9234  \n",
       "19             0.9301  \n",
       "20             0.8981  \n",
       "21             0.9375  \n",
       "22             0.8234  \n",
       "23             0.9154  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('data/pca.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapper methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = [10, 50, 100]\n",
    "selector = [RFE(estimator=RandomForestClassifier(n_estimators=100, max_depth=3), n_features_to_select=7000, step=1, verbose=0)]\n",
    "rfe_results = full_evaluation(train_data, train_labels, valid_data, valid_labels, selector, classifiers, dataset_type='sms')\n",
    "rfe_results.to_csv('data/RFE.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeded methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_df = pd.DataFrame(columns=['Selector', 'Classifier', 'Number_of_Features', 'Accuracy', 'Performance_score'])\n",
    "Cs = [0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "for C in Cs:\n",
    "    lasso = LogisticRegression(penalty='l1', C=C, solver='liblinear', random_state=0)\n",
    "    lasso.fit(train_data, train_labels)\n",
    "    n_features = sum(lasso.coef_[0] != 0)\n",
    "    score = lasso.score(valid_data, valid_labels)\n",
    "    perf_score = performance_score(score, n_features, dataset_type='sms')\n",
    "    lasso_df = pd.concat([lasso_df, pd.DataFrame({'Selector': ['Lasso'], 'Classifier': ['Lasso'], 'Number_of_Features': [n_features], 'Accuracy': [score], 'Performance_score': [perf_score]})], ignore_index=True)\n",
    "\n",
    "lasso_df.to_csv('data/lasso.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "l1_ratio = [0.9, 0.95, 0.98]\n",
    "elastic_df = pd.DataFrame(columns=['Selector', 'Classifier', 'Number_of_Features', 'Accuracy', 'Performance_score', 'alpha', 'l1_ratio'])\n",
    "for ratio in l1_ratio:\n",
    "    for alpha in alphas:\n",
    "        elastic = ElasticNet(alpha=alpha, l1_ratio=ratio, random_state=0, max_iter = 10000)\n",
    "        elastic.fit(train_data, train_labels)\n",
    "        n_features = sum(elastic.coef_!= 0)\n",
    "        score = elastic.score(valid_data, valid_labels)\n",
    "        perf_score = performance_score(score, n_features, dataset_type='sms')\n",
    "        elastic_df = pd.concat([elastic_df, pd.DataFrame({'Selector': ['Lasso'], 'Classifier': ['Lasso'], 'Number_of_Features': [n_features], 'Accuracy': [score], 'Performance_score': [perf_score], \"alpha\": [alpha], \"l1_ratio\": [ratio]})], ignore_index=True)\n",
    "\n",
    "elastic_df.to_csv('data/elasticNet.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "elasticNet = pd.read_csv('data2/elasticNet.csv')\n",
    "elasticNet['Selector'] = 'ElasticNet'\n",
    "elasticNet['Classifier'] = 'ElasticNet'\n",
    "elasticNet.to_csv('data/elasticNet.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = [10, 20, 30, 50, 75, 100, 200]\n",
    "forest_results = pd.DataFrame()\n",
    "for n in n_features:\n",
    "    selector = [RandomForestSelector(n_features=n)]\n",
    "    df = full_evaluation(train_data, train_labels, valid_data, valid_labels, selector, classifiers, dataset_type='sms')\n",
    "    forest_results = pd.concat([forest_results, df])\n",
    "forest_results.to_csv('data/forest.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = [10, 20, 30, 50, 75, 100, 200]\n",
    "corr_results = pd.DataFrame()\n",
    "for n in n_features:\n",
    "    selector = [CorrelationSelector(n_features=n)]\n",
    "    df = full_evaluation(train_data, train_labels, valid_data, valid_labels, selector, classifiers, dataset_type='sms')\n",
    "    corr_results = pd.concat([corr_results, df])\n",
    "corr_results.to_csv('data/corr.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = [10, 20, 30, 50, 75, 100, 200]\n",
    "mutual_results = pd.DataFrame()\n",
    "for n in n_features:\n",
    "    selector = [MutualInformationSelector(n_features=n)]\n",
    "    df = full_evaluation(train_data, train_labels, valid_data, valid_labels, selector, classifiers, dataset_type='sms')\n",
    "    mutual_results = pd.concat([mutual_results, df])\n",
    "mutual_results.to_csv('data/mutual.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select K - Best"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = [10, 20, 30, 50, 75, 100, 200]\n",
    "anova_results = pd.DataFrame()\n",
    "for n in n_features:\n",
    "    selector = [SelectKBest(f_classif, k=n)]\n",
    "    df = full_evaluation(train_data, train_labels, valid_data, valid_labels, selector, classifiers, dataset_type='sms')\n",
    "    anova_results = pd.concat([anova_results, df])\n",
    "anova_results.to_csv('data/anova.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = [10, 20, 30, 50, 75, 100, 200]\n",
    "chi2_results = pd.DataFrame()\n",
    "for n in n_features:\n",
    "    selector = [SelectKBest(chi2, k=n)]\n",
    "    df = full_evaluation(train_data, train_labels, valid_data, valid_labels, selector, classifiers, dataset_type='sms')\n",
    "    chi2_results = pd.concat([chi2_results, df])\n",
    "chi2_results.to_csv('data/chi2.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid + wrapper"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boruta algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = [BorutaPy(estimator=RandomForestClassifier(n_estimators=100, max_depth=3), n_estimators='auto', verbose=1, random_state=0)]\n",
    "boruta_results = full_evaluation(train_data, train_labels, valid_data, valid_labels, selector, classifiers, dataset_type='sms')\n",
    "boruta_results.to_csv('data/boruta.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features_rfs = [100, 200]\n",
    "n_features_rfe = [10, 25, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 100 features.\n",
      "Fitting estimator with 99 features.\n",
      "Fitting estimator with 98 features.\n",
      "Fitting estimator with 97 features.\n",
      "Fitting estimator with 96 features.\n",
      "Fitting estimator with 95 features.\n",
      "Fitting estimator with 94 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 92 features.\n",
      "Fitting estimator with 91 features.\n",
      "Fitting estimator with 90 features.\n",
      "Fitting estimator with 89 features.\n",
      "Fitting estimator with 88 features.\n",
      "Fitting estimator with 87 features.\n",
      "Fitting estimator with 86 features.\n",
      "Fitting estimator with 85 features.\n",
      "Fitting estimator with 84 features.\n",
      "Fitting estimator with 83 features.\n",
      "Fitting estimator with 82 features.\n",
      "Fitting estimator with 81 features.\n",
      "Fitting estimator with 80 features.\n",
      "Fitting estimator with 79 features.\n",
      "Fitting estimator with 78 features.\n",
      "Fitting estimator with 77 features.\n",
      "Fitting estimator with 76 features.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m selector2 \u001b[39m=\u001b[39m RFE(estimator\u001b[39m=\u001b[39mRandomForestClassifier(n_estimators\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, max_depth\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m), n_features_to_select\u001b[39m=\u001b[39mm, step\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      6\u001b[0m selectors \u001b[39m=\u001b[39m [[selector1, selector2]]\n\u001b[1;32m----> 7\u001b[0m df \u001b[39m=\u001b[39m full_evaluation(train_data, train_labels, valid_data, valid_labels, selectors, classifiers, dataset_type\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39martificial\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      8\u001b[0m stack_results \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([stack_results, df])\n\u001b[0;32m      9\u001b[0m stack_results\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39mdata/stack.csv\u001b[39m\u001b[39m'\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\jan20\\OneDrive\\Pulpit\\DS\\sem2\\Advanced_Machine_ Learning\\Advanced_Machine_Learning\\Project2\\feature_selection_package\\evaluation.py:84\u001b[0m, in \u001b[0;36mfull_evaluation\u001b[1;34m(X_train, y_train, X_val, y_val, selectors, classifiers, dataset_type)\u001b[0m\n\u001b[0;32m     81\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mSelector\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mClassifier\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mNumber_of_Features\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAccuracy\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mPerformance_score\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     83\u001b[0m \u001b[39mfor\u001b[39;00m selector \u001b[39min\u001b[39;00m selectors:\n\u001b[1;32m---> 84\u001b[0m     feature_selection_pipeline \u001b[39m=\u001b[39m feature_selection(X_train, y_train, selector)\n\u001b[0;32m     85\u001b[0m     \u001b[39mfor\u001b[39;00m classifier \u001b[39min\u001b[39;00m classifiers:\n\u001b[0;32m     86\u001b[0m         accuracy, perf_score, n_features \u001b[39m=\u001b[39m single_evaluation(X_train, y_train, X_val, y_val, feature_selection_pipeline, classifier, dataset_type)\n",
      "File \u001b[1;32mc:\\Users\\jan20\\OneDrive\\Pulpit\\DS\\sem2\\Advanced_Machine_ Learning\\Advanced_Machine_Learning\\Project2\\feature_selection_package\\evaluation.py:38\u001b[0m, in \u001b[0;36mfeature_selection\u001b[1;34m(X, y, selectors, scaler)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     37\u001b[0m     pipeline \u001b[39m=\u001b[39m make_pipeline(scaler, selectors)\n\u001b[1;32m---> 38\u001b[0m pipeline\u001b[39m.\u001b[39;49mfit_transform(X, y) \n\u001b[0;32m     40\u001b[0m \u001b[39mreturn\u001b[39;00m pipeline\n",
      "File \u001b[1;32mc:\\Users\\jan20\\PycharmProjects\\PytorchProjects\\venv\\lib\\site-packages\\sklearn\\pipeline.py:422\u001b[0m, in \u001b[0;36mPipeline.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    420\u001b[0m fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[0;32m    421\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(last_step, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 422\u001b[0m     \u001b[39mreturn\u001b[39;00m last_step\u001b[39m.\u001b[39mfit_transform(Xt, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_last_step)\n\u001b[0;32m    423\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    424\u001b[0m     \u001b[39mreturn\u001b[39;00m last_step\u001b[39m.\u001b[39mfit(Xt, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_last_step)\u001b[39m.\u001b[39mtransform(Xt)\n",
      "File \u001b[1;32mc:\\Users\\jan20\\PycharmProjects\\PytorchProjects\\venv\\lib\\site-packages\\sklearn\\base.py:870\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    867\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[0;32m    868\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    869\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m--> 870\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\jan20\\PycharmProjects\\PytorchProjects\\venv\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:235\u001b[0m, in \u001b[0;36mRFE.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params):\n\u001b[0;32m    216\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Fit the RFE model and then the underlying estimator on the selected features.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \n\u001b[0;32m    218\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    234\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 235\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n",
      "File \u001b[1;32mc:\\Users\\jan20\\PycharmProjects\\PytorchProjects\\venv\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:296\u001b[0m, in \u001b[0;36mRFE._fit\u001b[1;34m(self, X, y, step_score, **fit_params)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    294\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFitting estimator with \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m features.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m np\u001b[39m.\u001b[39msum(support_))\n\u001b[1;32m--> 296\u001b[0m estimator\u001b[39m.\u001b[39mfit(X[:, features], y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    298\u001b[0m \u001b[39m# Get importance and rank them\u001b[39;00m\n\u001b[0;32m    299\u001b[0m importances \u001b[39m=\u001b[39m _get_feature_importances(\n\u001b[0;32m    300\u001b[0m     estimator,\n\u001b[0;32m    301\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimportance_getter,\n\u001b[0;32m    302\u001b[0m     transform_func\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msquare\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    303\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\jan20\\PycharmProjects\\PytorchProjects\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:465\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwarm_start \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    461\u001b[0m     \u001b[39m# We draw from the random state to get the random state we\u001b[39;00m\n\u001b[0;32m    462\u001b[0m     \u001b[39m# would have got if we hadn't used a warm_start.\u001b[39;00m\n\u001b[0;32m    463\u001b[0m     random_state\u001b[39m.\u001b[39mrandint(MAX_INT, size\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_))\n\u001b[1;32m--> 465\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[0;32m    466\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m    467\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    468\u001b[0m ]\n\u001b[0;32m    470\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    473\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    475\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m    476\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[0;32m    477\u001b[0m     n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs,\n\u001b[0;32m    478\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    493\u001b[0m     \u001b[39mfor\u001b[39;00m i, t \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(trees)\n\u001b[0;32m    494\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\jan20\\PycharmProjects\\PytorchProjects\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:466\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwarm_start \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    461\u001b[0m     \u001b[39m# We draw from the random state to get the random state we\u001b[39;00m\n\u001b[0;32m    462\u001b[0m     \u001b[39m# would have got if we hadn't used a warm_start.\u001b[39;00m\n\u001b[0;32m    463\u001b[0m     random_state\u001b[39m.\u001b[39mrandint(MAX_INT, size\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_))\n\u001b[0;32m    465\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[1;32m--> 466\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_estimator(append\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, random_state\u001b[39m=\u001b[39;49mrandom_state)\n\u001b[0;32m    467\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    468\u001b[0m ]\n\u001b[0;32m    470\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    473\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    475\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m    476\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[0;32m    477\u001b[0m     n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs,\n\u001b[0;32m    478\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    493\u001b[0m     \u001b[39mfor\u001b[39;00m i, t \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(trees)\n\u001b[0;32m    494\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\jan20\\PycharmProjects\\PytorchProjects\\venv\\lib\\site-packages\\sklearn\\ensemble\\_base.py:186\u001b[0m, in \u001b[0;36mBaseEnsemble._make_estimator\u001b[1;34m(self, append, random_state)\u001b[0m\n\u001b[0;32m    183\u001b[0m             estimator\u001b[39m.\u001b[39mset_params(max_features\u001b[39m=\u001b[39m\u001b[39m1.0\u001b[39m)\n\u001b[0;32m    185\u001b[0m \u001b[39mif\u001b[39;00m random_state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 186\u001b[0m     _set_random_states(estimator, random_state)\n\u001b[0;32m    188\u001b[0m \u001b[39mif\u001b[39;00m append:\n\u001b[0;32m    189\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mappend(estimator)\n",
      "File \u001b[1;32mc:\\Users\\jan20\\PycharmProjects\\PytorchProjects\\venv\\lib\\site-packages\\sklearn\\ensemble\\_base.py:81\u001b[0m, in \u001b[0;36m_set_random_states\u001b[1;34m(estimator, random_state)\u001b[0m\n\u001b[0;32m     79\u001b[0m random_state \u001b[39m=\u001b[39m check_random_state(random_state)\n\u001b[0;32m     80\u001b[0m to_set \u001b[39m=\u001b[39m {}\n\u001b[1;32m---> 81\u001b[0m \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(estimator\u001b[39m.\u001b[39;49mget_params(deep\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)):\n\u001b[0;32m     82\u001b[0m     \u001b[39mif\u001b[39;00m key \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrandom_state\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m key\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m__random_state\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     83\u001b[0m         to_set[key] \u001b[39m=\u001b[39m random_state\u001b[39m.\u001b[39mrandint(np\u001b[39m.\u001b[39miinfo(np\u001b[39m.\u001b[39mint32)\u001b[39m.\u001b[39mmax)\n",
      "File \u001b[1;32mc:\\Users\\jan20\\PycharmProjects\\PytorchProjects\\venv\\lib\\site-packages\\sklearn\\base.py:210\u001b[0m, in \u001b[0;36mBaseEstimator.get_params\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[39mGet parameters for this estimator.\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[39m    Parameter names mapped to their values.\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    209\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m()\n\u001b[1;32m--> 210\u001b[0m \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_param_names():\n\u001b[0;32m    211\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, key)\n\u001b[0;32m    212\u001b[0m     \u001b[39mif\u001b[39;00m deep \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(value, \u001b[39m\"\u001b[39m\u001b[39mget_params\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(value, \u001b[39mtype\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\jan20\\PycharmProjects\\PytorchProjects\\venv\\lib\\site-packages\\sklearn\\base.py:175\u001b[0m, in \u001b[0;36mBaseEstimator._get_param_names\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[39mreturn\u001b[39;00m []\n\u001b[0;32m    173\u001b[0m \u001b[39m# introspect the constructor arguments to find the model parameters\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[39m# to represent\u001b[39;00m\n\u001b[1;32m--> 175\u001b[0m init_signature \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39;49msignature(init)\n\u001b[0;32m    176\u001b[0m \u001b[39m# Consider the constructor parameters excluding 'self'\u001b[39;00m\n\u001b[0;32m    177\u001b[0m parameters \u001b[39m=\u001b[39m [\n\u001b[0;32m    178\u001b[0m     p\n\u001b[0;32m    179\u001b[0m     \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m init_signature\u001b[39m.\u001b[39mparameters\u001b[39m.\u001b[39mvalues()\n\u001b[0;32m    180\u001b[0m     \u001b[39mif\u001b[39;00m p\u001b[39m.\u001b[39mname \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m p\u001b[39m.\u001b[39mkind \u001b[39m!=\u001b[39m p\u001b[39m.\u001b[39mVAR_KEYWORD\n\u001b[0;32m    181\u001b[0m ]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\inspect.py:3247\u001b[0m, in \u001b[0;36msignature\u001b[1;34m(obj, follow_wrapped, globals, locals, eval_str)\u001b[0m\n\u001b[0;32m   3245\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msignature\u001b[39m(obj, \u001b[39m*\u001b[39m, follow_wrapped\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, \u001b[39mglobals\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39mlocals\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, eval_str\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m   3246\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get a signature object for the passed callable.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 3247\u001b[0m     \u001b[39mreturn\u001b[39;00m Signature\u001b[39m.\u001b[39;49mfrom_callable(obj, follow_wrapped\u001b[39m=\u001b[39;49mfollow_wrapped,\n\u001b[0;32m   3248\u001b[0m                                    \u001b[39mglobals\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mglobals\u001b[39;49m, \u001b[39mlocals\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mlocals\u001b[39;49m, eval_str\u001b[39m=\u001b[39;49meval_str)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\inspect.py:2995\u001b[0m, in \u001b[0;36mSignature.from_callable\u001b[1;34m(cls, obj, follow_wrapped, globals, locals, eval_str)\u001b[0m\n\u001b[0;32m   2991\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m   2992\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_callable\u001b[39m(\u001b[39mcls\u001b[39m, obj, \u001b[39m*\u001b[39m,\n\u001b[0;32m   2993\u001b[0m                   follow_wrapped\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, \u001b[39mglobals\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39mlocals\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, eval_str\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m   2994\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Constructs Signature for the given callable object.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 2995\u001b[0m     \u001b[39mreturn\u001b[39;00m _signature_from_callable(obj, sigcls\u001b[39m=\u001b[39;49m\u001b[39mcls\u001b[39;49m,\n\u001b[0;32m   2996\u001b[0m                                     follow_wrapper_chains\u001b[39m=\u001b[39;49mfollow_wrapped,\n\u001b[0;32m   2997\u001b[0m                                     \u001b[39mglobals\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mglobals\u001b[39;49m, \u001b[39mlocals\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mlocals\u001b[39;49m, eval_str\u001b[39m=\u001b[39;49meval_str)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\inspect.py:2456\u001b[0m, in \u001b[0;36m_signature_from_callable\u001b[1;34m(obj, follow_wrapper_chains, skip_bound_arg, globals, locals, eval_str, sigcls)\u001b[0m\n\u001b[0;32m   2451\u001b[0m             \u001b[39mreturn\u001b[39;00m sig\u001b[39m.\u001b[39mreplace(parameters\u001b[39m=\u001b[39mnew_params)\n\u001b[0;32m   2453\u001b[0m \u001b[39mif\u001b[39;00m isfunction(obj) \u001b[39mor\u001b[39;00m _signature_is_functionlike(obj):\n\u001b[0;32m   2454\u001b[0m     \u001b[39m# If it's a pure Python function, or an object that is duck type\u001b[39;00m\n\u001b[0;32m   2455\u001b[0m     \u001b[39m# of a Python function (Cython functions, for instance), then:\u001b[39;00m\n\u001b[1;32m-> 2456\u001b[0m     \u001b[39mreturn\u001b[39;00m _signature_from_function(sigcls, obj,\n\u001b[0;32m   2457\u001b[0m                                     skip_bound_arg\u001b[39m=\u001b[39;49mskip_bound_arg,\n\u001b[0;32m   2458\u001b[0m                                     \u001b[39mglobals\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mglobals\u001b[39;49m, \u001b[39mlocals\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mlocals\u001b[39;49m, eval_str\u001b[39m=\u001b[39;49meval_str)\n\u001b[0;32m   2460\u001b[0m \u001b[39mif\u001b[39;00m _signature_is_builtin(obj):\n\u001b[0;32m   2461\u001b[0m     \u001b[39mreturn\u001b[39;00m _signature_from_builtin(sigcls, obj,\n\u001b[0;32m   2462\u001b[0m                                    skip_bound_arg\u001b[39m=\u001b[39mskip_bound_arg)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\inspect.py:2350\u001b[0m, in \u001b[0;36m_signature_from_function\u001b[1;34m(cls, func, skip_bound_arg, globals, locals, eval_str)\u001b[0m\n\u001b[0;32m   2347\u001b[0m         default \u001b[39m=\u001b[39m kwdefaults\u001b[39m.\u001b[39mget(name, _empty)\n\u001b[0;32m   2349\u001b[0m     annotation \u001b[39m=\u001b[39m annotations\u001b[39m.\u001b[39mget(name, _empty)\n\u001b[1;32m-> 2350\u001b[0m     parameters\u001b[39m.\u001b[39mappend(Parameter(name, annotation\u001b[39m=\u001b[39;49mannotation,\n\u001b[0;32m   2351\u001b[0m                                 kind\u001b[39m=\u001b[39;49m_KEYWORD_ONLY,\n\u001b[0;32m   2352\u001b[0m                                 default\u001b[39m=\u001b[39;49mdefault))\n\u001b[0;32m   2353\u001b[0m \u001b[39m# **kwargs\u001b[39;00m\n\u001b[0;32m   2354\u001b[0m \u001b[39mif\u001b[39;00m func_code\u001b[39m.\u001b[39mco_flags \u001b[39m&\u001b[39m CO_VARKEYWORDS:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\inspect.py:2632\u001b[0m, in \u001b[0;36mParameter.__init__\u001b[1;34m(self, name, kind, default, annotation)\u001b[0m\n\u001b[0;32m   2630\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, kind, \u001b[39m*\u001b[39m, default\u001b[39m=\u001b[39m_empty, annotation\u001b[39m=\u001b[39m_empty):\n\u001b[0;32m   2631\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 2632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_kind \u001b[39m=\u001b[39m _ParameterKind(kind)\n\u001b[0;32m   2633\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[0;32m   2634\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mvalue \u001b[39m\u001b[39m{\u001b[39;00mkind\u001b[39m!r}\u001b[39;00m\u001b[39m is not a valid Parameter.kind\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\enum.py:385\u001b[0m, in \u001b[0;36mEnumMeta.__call__\u001b[1;34m(cls, value, names, module, qualname, type, start)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    361\u001b[0m \u001b[39mEither returns an existing member, or creates a new enum class.\u001b[39;00m\n\u001b[0;32m    362\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[39m`type`, if set, will be mixed in as the first base class.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \u001b[39mif\u001b[39;00m names \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# simple value lookup\u001b[39;00m\n\u001b[1;32m--> 385\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__new__\u001b[39;49m(\u001b[39mcls\u001b[39;49m, value)\n\u001b[0;32m    386\u001b[0m \u001b[39m# otherwise, functional API: we're creating a new Enum type\u001b[39;00m\n\u001b[0;32m    387\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_create_(\n\u001b[0;32m    388\u001b[0m         value,\n\u001b[0;32m    389\u001b[0m         names,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m         start\u001b[39m=\u001b[39mstart,\n\u001b[0;32m    394\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\enum.py:678\u001b[0m, in \u001b[0;36mEnum.__new__\u001b[1;34m(cls, value)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mEnum\u001b[39;00m(metaclass\u001b[39m=\u001b[39mEnumMeta):\n\u001b[0;32m    673\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    674\u001b[0m \u001b[39m    Generic enumeration.\u001b[39;00m\n\u001b[0;32m    675\u001b[0m \n\u001b[0;32m    676\u001b[0m \u001b[39m    Derive from this class to define new enumerations.\u001b[39;00m\n\u001b[0;32m    677\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 678\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__new__\u001b[39m(\u001b[39mcls\u001b[39m, value):\n\u001b[0;32m    679\u001b[0m         \u001b[39m# all enum instances are actually created during class construction\u001b[39;00m\n\u001b[0;32m    680\u001b[0m         \u001b[39m# without calling this method; this method is called by the metaclass'\u001b[39;00m\n\u001b[0;32m    681\u001b[0m         \u001b[39m# __call__ (i.e. Color(3) ), and by pickle\u001b[39;00m\n\u001b[0;32m    682\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(value) \u001b[39mis\u001b[39;00m \u001b[39mcls\u001b[39m:\n\u001b[0;32m    683\u001b[0m             \u001b[39m# For lookups like Color(Color.RED)\u001b[39;00m\n\u001b[0;32m    684\u001b[0m             \u001b[39mreturn\u001b[39;00m value\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "stack_results = pd.DataFrame()\n",
    "for n in n_features_rfs:\n",
    "    for m in n_features_rfe:\n",
    "        selector1 = RandomForestSelector(n_features=n)\n",
    "        selector2 = RFE(estimator=RandomForestClassifier(n_estimators=100, max_depth=3), n_features_to_select=m, step=1, verbose=1)\n",
    "        selectors = [[selector1, selector2]]\n",
    "        df = full_evaluation(train_data, train_labels, valid_data, valid_labels, selectors, classifiers, dataset_type='artificial')\n",
    "        stack_results = pd.concat([stack_results, df])\n",
    "        stack_results.to_csv('data/stack.csv', index=False)\n",
    "\n",
    "stack_results.to_csv('data/stack.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = [10, 20, 30, 50, 75, 100, 200]\n",
    "ensemble_results = pd.DataFrame()\n",
    "for n in n_features:\n",
    "    selectors = [RandomForestSelector(n_features=n), SelectKBest(f_classif, k=n), SelectKBest(chi2, k=n), CorrelationSelector(n_features=n), MutualInformationSelector(n_features=n)]\n",
    "    ensemble = [EnsembleSelector(selectors=selectors)]\n",
    "    df = full_evaluation(train_data, train_labels, valid_data, valid_labels, ensemble, classifiers, dataset_type='sms')\n",
    "    ensemble_results = pd.concat([ensemble_results, df])\n",
    "    \n",
    "ensemble_results.to_csv('data/ensemble.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
