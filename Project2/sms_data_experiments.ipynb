{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from boruta import BorutaPy\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SequentialFeatureSelector, RFE, mutual_info_classif, SelectKBest, f_classif, chi2\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV, ElasticNet\n",
    "from feature_selection_package.evaluation import performance_score, single_evaluation, full_evaluation\n",
    "from feature_selection_package.feature_selectors import CorrelationSelector, MutualInformationSelector, RandomForestSelector, EnsembleSelector\n",
    "from boruta import BorutaPy\n",
    "from feature_selection_package.sms_data_creation import get_word_counts_train_test\n",
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data sms\n",
    "sms_train = pd.read_csv('data/sms_train.csv')\n",
    "sms_train_data, sms_train_labels = sms_train.iloc[:, 1], sms_train.iloc[:, 0]\n",
    "\n",
    "sms_test_data = pd.read_csv('data/sms_test.csv')\n",
    "sms_test = sms_test_data.copy()\n",
    "sms_test['label'] = np.nan\n",
    "\n",
    "preprocessed_sms_train , preprocessed_sms_test = get_word_counts_train_test(sms_train, sms_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = preprocessed_sms_train.iloc[:np.round(len(preprocessed_sms_train)*0.8).astype(int), 1:]\n",
    "train_labels = preprocessed_sms_train.iloc[:np.round(len(preprocessed_sms_train)*0.8).astype(int), 0]\n",
    "valid_data = preprocessed_sms_train.iloc[np.round(len(preprocessed_sms_train)*0.8).astype(int):, 1:]\n",
    "valid_labels = preprocessed_sms_train.iloc[np.round(len(preprocessed_sms_train)*0.8).astype(int):, 0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if train and valid data is balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of observations in each class in train set: (array([0, 1], dtype=int64), array([3170,  488], dtype=int64))\n",
      "number of observations in each class in validation set: (array([0, 1], dtype=int64), array([789, 125], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print('number of observations in each class in train set:', np.unique(train_labels, return_counts=True))\n",
    "print('number of observations in each class in validation set:', np.unique(valid_labels, return_counts=True))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm1 = SVC(kernel='rbf', C=1, random_state=0)\n",
    "svm2 = SVC(kernel='linear', C=1, random_state=0)\n",
    "\n",
    "tree = DecisionTreeClassifier(criterion='entropy', max_depth=5, random_state=0)\n",
    "xgboost = XGBClassifier(learning_rate=0.1, n_estimators=100, max_depth=5, random_state=0)\n",
    "rfc = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=0)\n",
    "\n",
    "logreg = LogisticRegression(penalty='l2', C=1, random_state=0, max_iter=1000)\n",
    "\n",
    "classifiers = np.array([svm1, svm2, tree, xgboost, rfc, logreg])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality reduction methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = [10, 20, 30, 50, 75]\n",
    "pca_results = pd.DataFrame()\n",
    "for n in n_features:\n",
    "    selector = [PCA(n_components=n)]\n",
    "    pca_df = full_evaluation(train_data, train_labels, valid_data, valid_labels, selector, classifiers, dataset_type='sms')\n",
    "    pca_results = pd.concat([pca_results, pca_df])\n",
    "pca_results.to_csv('data/pca.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapper methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = [10, 50, 100]\n",
    "rfe_results = pd.DataFrame()\n",
    "for n in n_features:\n",
    "    selector = [RFE(estimator=RandomForestClassifier(n_estimators=100, max_depth=3), n_features_to_select=n, step=1, verbose=0)]\n",
    "    df = full_evaluation(train_data, train_labels, valid_data, valid_labels, selector, classifiers, dataset_type='sms')\n",
    "    rfe_results = pd.concat([rfe_results, df])\n",
    "rfe_results.to_csv('data/RFE.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeded methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_df = pd.DataFrame(columns=['Selector', 'Classifier', 'Number_of_Features', 'Accuracy', 'Performance_score', 'Supported_Features'])\n",
    "Cs = [0.001, 0.01, 0.05, 0.1, 0.5, 1, 10]\n",
    "for C in Cs:\n",
    "    lasso = LogisticRegression(penalty='l1', C=C, solver='liblinear', random_state=0)\n",
    "    lasso.fit(train_data, train_labels)\n",
    "    n_features = sum(lasso.coef_[0] != 0)\n",
    "    supported_features = (lasso.coef_[0] != 0)\n",
    "    score = balanced_accuracy_score(valid_labels, lasso.predict(valid_data))\n",
    "    perf_score = performance_score(score, n_features, dataset_type='sms')\n",
    "    lasso_df = pd.concat([lasso_df, pd.DataFrame({'Selector': ['Lasso'], 'Classifier': ['Lasso'], 'Number_of_Features': [n_features], 'Accuracy': [score], 'Performance_score': [perf_score], 'Supported_Features': [supported_features]})], ignore_index=True)\n",
    "\n",
    "lasso_df.to_csv('data/lasso.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0.001, 0.01, 0.05, 0.1, 0.5, 1, 10]\n",
    "l1_ratio = [0.5, 0.7, 0.9]\n",
    "elastic_df = pd.DataFrame(columns=['Selector', 'Classifier', 'Number_of_Features', 'Accuracy', 'Performance_score', 'alpha', 'l1_ratio', 'Supported_Features'])\n",
    "for ratio in l1_ratio:\n",
    "    for alpha in alphas:\n",
    "        elastic = ElasticNet(alpha=alpha, l1_ratio=ratio, random_state=0, max_iter = 10000)\n",
    "        elastic.fit(train_data, train_labels)\n",
    "        n_features = sum(elastic.coef_!= 0)\n",
    "        supported_features = (elastic.coef_[0] != 0)\n",
    "        y_pred = np.where(elastic.predict(valid_data) > 0.5, 1, 0)\n",
    "        score = balanced_accuracy_score(valid_labels, y_pred)\n",
    "        perf_score = performance_score(score, n_features, dataset_type='sms')\n",
    "        elastic_df = pd.concat([elastic_df, pd.DataFrame({'Selector': ['ElasticNet'], 'Classifier': ['ElasticNet'], 'Number_of_Features': [n_features], 'Accuracy': [score], 'Performance_score': [perf_score], \"alpha\": [alpha], \"l1_ratio\": [ratio], 'Supported_Features': [supported_features]})], ignore_index=True)\n",
    "\n",
    "elastic_df.to_csv('data/elasticNet.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = [10, 20, 30, 50, 75, 100, 200]\n",
    "forest_results = pd.DataFrame()\n",
    "for n in n_features:\n",
    "    selector = [RandomForestSelector(n_features=n)]\n",
    "    df = full_evaluation(train_data, train_labels, valid_data, valid_labels, selector, classifiers, dataset_type='sms')\n",
    "    forest_results = pd.concat([forest_results, df])\n",
    "forest_results.to_csv('data/forest.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = [10, 20, 30, 50, 75, 100, 200]\n",
    "corr_results = pd.DataFrame()\n",
    "for n in n_features:\n",
    "    selector = [CorrelationSelector(n_features=n)]\n",
    "    df = full_evaluation(train_data, train_labels, valid_data, valid_labels, selector, classifiers, dataset_type='sms')\n",
    "    corr_results = pd.concat([corr_results, df])\n",
    "corr_results.to_csv('data/corr.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = [10, 20, 30, 50, 75, 100, 200]\n",
    "mutual_results = pd.DataFrame()\n",
    "for n in n_features:\n",
    "    selector = [MutualInformationSelector(n_features=n)]\n",
    "    df = full_evaluation(train_data, train_labels, valid_data, valid_labels, selector, classifiers, dataset_type='sms')\n",
    "    mutual_results = pd.concat([mutual_results, df])\n",
    "mutual_results.to_csv('data/mutual.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select K - Best"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = [10, 20, 30, 50, 75, 100, 200]\n",
    "anova_results = pd.DataFrame()\n",
    "for n in n_features:\n",
    "    selector = [SelectKBest(f_classif, k=n)]\n",
    "    df = full_evaluation(train_data, train_labels, valid_data, valid_labels, selector, classifiers, dataset_type='sms')\n",
    "    anova_results = pd.concat([anova_results, df])\n",
    "anova_results.to_csv('data/anova.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = [10, 20, 30, 50, 75, 100, 200]\n",
    "chi2_results = pd.DataFrame()\n",
    "for n in n_features:\n",
    "    selector = [SelectKBest(chi2, k=n)]\n",
    "    df = full_evaluation(train_data, train_labels, valid_data, valid_labels, selector, classifiers, dataset_type='sms')\n",
    "    chi2_results = pd.concat([chi2_results, df])\n",
    "chi2_results.to_csv('data/chi2.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid + wrapper"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boruta algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = [BorutaPy(estimator=RandomForestClassifier(n_estimators=100, max_depth=3), n_estimators='auto', verbose=1, random_state=0)]\n",
    "boruta_results = full_evaluation(train_data, train_labels, valid_data, valid_labels, selector, classifiers, dataset_type='sms')\n",
    "boruta_results.to_csv('data/boruta.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features_rfs = [100, 200]\n",
    "n_features_rfe = [10, 25, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_results = pd.DataFrame()\n",
    "for n in n_features_rfs:\n",
    "    for m in n_features_rfe:\n",
    "        selector1 = RandomForestSelector(n_features=n)\n",
    "        selector2 = RFE(estimator=RandomForestClassifier(n_estimators=100, max_depth=3), n_features_to_select=m, step=1, verbose=1)\n",
    "        selectors = [[selector1, selector2]]\n",
    "        df = full_evaluation(train_data, train_labels, valid_data, valid_labels, selectors, classifiers, dataset_type='artificial')\n",
    "        stack_results = pd.concat([stack_results, df])\n",
    "        stack_results.to_csv('data/stack.csv', index=False)\n",
    "\n",
    "stack_results.to_csv('data/stack.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = [10, 20, 30, 50, 75, 100, 200]\n",
    "ensemble_results = pd.DataFrame()\n",
    "for n in n_features:\n",
    "    selectors = [RandomForestSelector(n_features=n), SelectKBest(f_classif, k=n), SelectKBest(chi2, k=n), CorrelationSelector(n_features=n), MutualInformationSelector(n_features=n)]\n",
    "    ensemble = [EnsembleSelector(selectors=selectors)]\n",
    "    df = full_evaluation(train_data, train_labels, valid_data, valid_labels, ensemble, classifiers, dataset_type='sms')\n",
    "    ensemble_results = pd.concat([ensemble_results, df])\n",
    "    \n",
    "ensemble_results.to_csv('data/ensemble.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
